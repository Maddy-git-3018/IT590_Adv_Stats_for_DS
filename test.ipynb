{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Function Approximation with Regularization\n",
    "Let \(f(x) = x + 2 \\cdot \\sin(0.5 \\cdot x)\) be the true function. We will generate data, fit models, and analyze overfitting and regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Data\n",
    "Generate 50 data points for \(x \\in [-10, 10]\) by adding Gaussian noise (mean = 0, variance = 0.5) to the true function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.linspace(-10, 10, 50)\n",
    "y_true = x + 2 * np.sin(0.5 * x)\n",
    "y_noisy = y_true + np.random.normal(0, np.sqrt(0.5), x.shape)\n",
    "\n",
    "plt.scatter(x, y_noisy, label='Noisy Data')\n",
    "plt.plot(x, y_true, color='red', label='True Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('True Function vs Noisy Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Optimal Model Capacity\n",
    "Fit polynomial models of varying degrees (model capacity) and plot training and generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_noisy, test_size=0.2, random_state=42)\n",
    "\n",
    "degrees = range(1, 15)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for degree in degrees:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0))\n",
    "    model.fit(x_train[:, np.newaxis], y_train)\n",
    "    y_train_pred = model.predict(x_train[:, np.newaxis])\n",
    "    y_test_pred = model.predict(x_test[:, np.newaxis])\n",
    "    train_errors.append(mean_squared_error(y_train, y_train_pred))\n",
    "    test_errors.append(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "plt.plot(degrees, train_errors, label='Training Error')\n",
    "plt.plot(degrees, test_errors, label='Test Error')\n",
    "plt.xlabel('Model Capacity (Degree)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.title('Training and Test Error vs Model Capacity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Addressing Overfitting and Regularization\n",
    "### 3.1 Use More Data\n",
    "Generate 100 data points and compare the learned curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_more = np.linspace(-10, 10, 100)\n",
    "y_more_noisy = x_more + 2 * np.sin(0.5 * x_more) + np.random.normal(0, np.sqrt(0.5), x_more.shape)\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(10), Ridge(alpha=0))\n",
    "model.fit(x[:, np.newaxis], y_noisy)\n",
    "y_pred_original = model.predict(x[:, np.newaxis])\n",
    "\n",
    "model.fit(x_more[:, np.newaxis], y_more_noisy)\n",
    "y_pred_more = model.predict(x_more[:, np.newaxis])\n",
    "\n",
    "plt.plot(x, y_true, label='True Function')\n",
    "plt.plot(x, y_pred_original, label='Original Data Fit')\n",
    "plt.plot(x_more, y_pred_more, label='More Data Fit')\n",
    "plt.legend()\n",
    "plt.title('Effect of More Data on Overfitting')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Lasso Regression\n",
    "Perform Lasso regression and analyze the effect of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.arange(0, 5.5, 0.5)\n",
    "train_errors_lasso = []\n",
    "test_errors_lasso = []\n",
    "non_zero_components = []\n",
    "\n",
    "for l in lambdas:\n",
    "    model = make_pipeline(PolynomialFeatures(10), Lasso(alpha=l))\n",
    "    model.fit(x_train[:, np.newaxis], y_train)\n",
    "    y_train_pred = model.predict(x_train[:, np.newaxis])\n",
    "    y_test_pred = model.predict(x_test[:, np.newaxis])\n",
    "    train_errors_lasso.append(mean_squared_error(y_train, y_train_pred))\n",
    "    test_errors_lasso.append(mean_squared_error(y_test, y_test_pred))\n",
    "    non_zero_components.append(np.sum(model.named_steps['lasso'].coef_ != 0))\n",
    "\n",
    "plt.plot(lambdas, train_errors_lasso, label='Training Error')\n",
    "plt.plot(lambdas, test_errors_lasso, label='Test Error')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.title('Lasso Regression: Training and Test Error vs Lambda')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lambdas, non_zero_components, marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Non-zero Components')\n",
    "plt.title('Lasso Regression: Non-zero Components vs Lambda')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ridge Regression\n",
    "Perform Ridge regression and analyze the effect of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors_ridge = []\n",
    "test_errors_ridge = []\n",
    "\n",
    "for l in lambdas:\n",
    "    model = make_pipeline(PolynomialFeatures(10), Ridge(alpha=l))\n",
    "    model.fit(x_train[:, np.newaxis], y_train)\n",
    "    y_train_pred = model.predict(x_train[:, np.newaxis])\n",
    "    y_test_pred = model.predict(x_test[:, np.newaxis])\n",
    "    train_errors_ridge.append(mean_squared_error(y_train, y_train_pred))\n",
    "    test_errors_ridge.append(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "plt.plot(lambdas, train_errors_ridge, label='Training Error')\n",
    "plt.plot(lambdas, test_errors_ridge, label='Test Error')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.title('Ridge Regression: Training and Test Error vs Lambda')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
